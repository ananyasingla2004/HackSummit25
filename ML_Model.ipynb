{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g1/rf8rhd995yb3nbyb003fgptc0000gn/T/ipykernel_1551/1191519326.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill for missing values\n",
      "/var/folders/g1/rf8rhd995yb3nbyb003fgptc0000gn/T/ipykernel_1551/1191519326.py:31: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(clean_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete for first chunk. Saved as cleaned_dataset_chunk.csv and preprocessed_data_chunk.csv\n"
     ]
    }
   ],
   "source": [
    "# Load dataset (only first chunk for testing)\n",
    "chunk_size = 1000000  # Adjust based on memory constraints\n",
    "chunks = pd.read_csv(\"en.openfoodfacts.org.products.csv\", low_memory=False, chunksize=chunk_size, sep=\"\\t\", on_bad_lines='skip')\n",
    "# chunks = pd.read_csv(\"en.openfoodfacts.org.products.csv\", low_memory=False, sep=\"\\t\", on_bad_lines='skip')\n",
    "\n",
    "df = next(chunks)  # Process only the first chunk\n",
    "\n",
    "# 1. Handling Missing Values\n",
    "df.fillna(method='ffill', inplace=True)  # Forward fill for missing values\n",
    "\n",
    "# 2. Data Type Conversion\n",
    "datetime_cols = ['created_datetime', 'last_modified_datetime', 'last_updated_datetime']\n",
    "numeric_cols = [col for col in df.columns if '_100g' in col or col in ['nutriscore_score', 'nova_group']]\n",
    "\n",
    "df[datetime_cols] = df[datetime_cols].apply(lambda x: pd.to_datetime(x, errors='coerce') if x.name in df.columns else x)\n",
    "df[numeric_cols] = df[numeric_cols].apply(lambda x: pd.to_numeric(x, errors='coerce') if x.name in df.columns else x)\n",
    "\n",
    "# 3. Reducing Memory Usage\n",
    "df[numeric_cols] = df[numeric_cols].astype('float32')\n",
    "\n",
    "# 4. Filtering Rows: Keep only products sold in India\n",
    "if 'countries' in df.columns:\n",
    "    df = df[df['countries'].str.contains('India', na=False, case=False)]\n",
    "\n",
    "# 5. Cleaning Text Fields\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.strip().replace('\\n', ' ').replace('\\r', '').lower()\n",
    "    return text\n",
    "\n",
    "df = df.applymap(clean_text)\n",
    "\n",
    "# 6. Handling Duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 7. Standardizing Units: Convert kcal to kJ (1 kcal = 4.184 kJ)\n",
    "if 'energy-kcal_100g' in df.columns:\n",
    "    df['energy-kj_100g'] = df['energy-kcal_100g'] * 4.184\n",
    "\n",
    "# Save preprocessed data\n",
    "df.to_csv(\"cleaned_dataset_chunk.csv\", index=False)\n",
    "df.to_csv(\"preprocessed_data_chunk.csv\", index=False)\n",
    "\n",
    "print(\"Data preprocessing complete for first chunk. Saved as cleaned_dataset_chunk.csv and preprocessed_data_chunk.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"cleaned_dataset_chunk.csv\", dtype={'code': str})\n",
    "\n",
    "# Drop columns with all NaN values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Identify numeric features\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Fill missing values in numeric features with the median\n",
    "df[numeric_features] = df[numeric_features].fillna(df[numeric_features].median())\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "\n",
    "# Train Nearest Neighbors model\n",
    "nn_model = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "nn_model.fit(df[numeric_features])\n",
    "\n",
    "def suggest_alternative(barcode):\n",
    "    barcode = str(barcode)  # Ensure barcode is treated as a string\n",
    "    product = df[df['code'] == barcode]\n",
    "    if product.empty:\n",
    "        return \"Product not found\"\n",
    "    \n",
    "    print(f\"Product Name: {product['product_name'].values[0]}\")\n",
    "    \n",
    "    product_features = product[numeric_features].fillna(0)\n",
    "    product_features = scaler.transform(product_features)\n",
    "    \n",
    "    # Check for NaN values\n",
    "    if np.isnan(product_features).any():\n",
    "        print(\"Warning: NaN values found in product_features after filling.\")\n",
    "        product_features = np.nan_to_num(product_features)\n",
    "    \n",
    "    distances, indices = nn_model.kneighbors(product_features)\n",
    "    \n",
    "    original_palm_oil = product['palmitic-acid_100g'].values[0]\n",
    "    alternatives = []\n",
    "    \n",
    "    for idx in indices[0]:\n",
    "        alternative = df.iloc[idx]\n",
    "        alternative_palm_oil = alternative['palmitic-acid_100g']\n",
    "        if 0 < alternative_palm_oil < original_palm_oil:  # Relatively less palm oil\n",
    "            alternatives.append(alternative[['code', 'product_name', 'palmitic-acid_100g']])\n",
    "    \n",
    "    return alternatives if alternatives else \"No suitable alternative found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name: kitkat chunky peanut butter\n",
      "No suitable alternative found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "barcode_input = \"804410415009\"  # Example barcode\n",
    "print(suggest_alternative(barcode_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
